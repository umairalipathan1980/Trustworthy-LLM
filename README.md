# Trustworthy-LLM
The code in this jupyter notebook generates a trustworthiness or reliability score of a large language model's response for both direct questions and retrieval augment generation (RAG).

